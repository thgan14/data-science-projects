{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Build a scrapper that scrapes at least a 1000 posts each from 2 different subreddits. This data will be the basis of our classification model that will predict which subreddit an unseen post belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping directly from reddit's API has been unsuccessful as there is a cap of 1000 unique posts returned. The scrapper only returned about 800 unique posts from each subreddit despite getting 2,500 total posts. An alternative was to use the PushShift API. PushShift is website that maintains and tracks social media data, they maintain a database for all reddit posts and do not have a total cap on retrievable posts. A link to it's API documentation can be found here:\n",
    "https://pushshift.io/api-parameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\"sort_type\":['score','score','created_utc'],\n",
    "     \"score\":[\">100\",\">100\",\">100\"],\n",
    "     \"sort\":[\"desc\",\"asc\",\"desc\"],\n",
    "    }\n",
    "\n",
    "def reddit_scrape(subreddit,params=p,before=1559347200,after=1514764800):\n",
    "    '''\n",
    "    This function scrapes reddit using the pushshift database to extract posts which follow criteria given by params\n",
    "    dictionary.\n",
    "\n",
    "    Before default date - 1 Jun 2019\n",
    "    After default date - 1 Jan 2018\n",
    "\n",
    "    We will use this date range to extract 1,500 posts from each subreddit for our training dataset. We will test on\n",
    "    posts from 1 Jun 2019 onwards. There may be duplicates in this requested 1500 posts, the function will drop duplicates\n",
    "    before returning\n",
    "\n",
    "    Params argument must be a dict. Keys must be pushshift api parameters and values must be a list, each of equal length\n",
    "\n",
    "    This function will return a dataframe\n",
    "    '''\n",
    "    dic = {'title':[],\n",
    "           'subreddit':[],\n",
    "            'score':[]}\n",
    "    p = params\n",
    "    assert len(p[list(p)[0]]) == len(p[list(p)[1]])\n",
    "    assert len(p[list(p)[1]]) == len(p[list(p)[2]])\n",
    "    its = len(p[list(p)[2]])\n",
    "    url = \"https://api.pushshift.io/reddit/search/submission/?after={}&before={}&limit=500\".format(after,before)\n",
    "    url +=\"&subreddit={}\".format(subreddit)\n",
    "    for i in range(its):\n",
    "        temp_url = url + \"&\" + list(p)[0] + \"=\" + p[list(p)[0]][i]\n",
    "        temp_url = temp_url +  \"&\" + list(p)[1] + \"=\" + p[list(p)[1]][i]\n",
    "        temp_url = temp_url +  \"&\" + list(p)[2] + \"=\" + p[list(p)[2]][i]\n",
    "        h = requests.get(temp_url,headers={'User-agent': \"Agent1\"}).json()\n",
    "        for d in h['data']:\n",
    "            dic['title'].append(d['title'])\n",
    "            dic['subreddit'].append(d['subreddit'])\n",
    "            dic['score'].append(d['score'])\n",
    "    df = pd.DataFrame(dic)\n",
    "    df=df.drop_duplicates('title')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wn is Worldnews subreddit, til is TodayILearned subreddit\n",
    "wn_train = reddit_scrape(\"worldnews\",p)\n",
    "til_train = reddit_scrape(\"todayilearned\",p)\n",
    "wn_test = reddit_scrape(\"worldnews\",p,after =1559347200,before=1575361406)\n",
    "til_test = reddit_scrape(\"todayilearned\",p,after =1559347200,before=1575361406)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wn_train.append(til_train)\n",
    "train['subreddit'] = train['subreddit'].map({'worldnews':1,'todayilearned':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = wn_test.append(til_test)\n",
    "test['subreddit'] = test['subreddit'].map({'worldnews':1,'todayilearned':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Two weeks before his inauguration, Donald J. T...</td>\n",
       "      <td>1</td>\n",
       "      <td>188216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mozilla launches 'Facebook Container' extensio...</td>\n",
       "      <td>1</td>\n",
       "      <td>138669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Italy bans unvaccinated children from school</td>\n",
       "      <td>1</td>\n",
       "      <td>123971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Bill and Melinda Gates sue company that was gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>123027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>'We Don't Know a Planet Like This': CO2 Levels...</td>\n",
       "      <td>1</td>\n",
       "      <td>121007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  subreddit   score\n",
       "0  Two weeks before his inauguration, Donald J. T...          1  188216\n",
       "1  Mozilla launches 'Facebook Container' extensio...          1  138669\n",
       "2       Italy bans unvaccinated children from school          1  123971\n",
       "3  Bill and Melinda Gates sue company that was gr...          1  123027\n",
       "4  'We Don't Know a Planet Like This': CO2 Levels...          1  121007"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics of our train & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data: 2954\n",
      "Length of test data: 2873\n",
      "No. of Worldnews subreddit in training data: 1470\n",
      "No. of todayilearned subreddit in training data: 1484\n",
      "No. of Worldnews subreddit in test data: 1425\n",
      "No. of todayilearned subreddit in test data: 1448\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training data: {}\".format(len(train)))\n",
    "print(\"Length of test data: {}\".format(len(test)))\n",
    "print(\"No. of Worldnews subreddit in training data: {}\".format(len(train.loc[train['subreddit']==1])))\n",
    "print(\"No. of todayilearned subreddit in training data: {}\".format(len(train.loc[train['subreddit']==0])))\n",
    "print(\"No. of Worldnews subreddit in test data: {}\".format(len(test.loc[test['subreddit']==1])))\n",
    "print(\"No. of todayilearned subreddit in test data: {}\".format(len(test.loc[test['subreddit']==0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('score',axis=1,inplace=True)\n",
    "test.drop('score',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\",index=False)\n",
    "test.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TIL that in 1916 there was a proposed Amendmen...</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>148135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TIL After Col. Shaw died in battle, Confederat...</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>137547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TIL of Dr. Donald Hopkins. He helped eradicate...</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>134330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TIL A Japanese company has awarded its non-smo...</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>131958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TIL Madonna leaked a fake version of her album...</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>124754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      subreddit   score\n",
       "0  TIL that in 1916 there was a proposed Amendmen...  todayilearned  148135\n",
       "1  TIL After Col. Shaw died in battle, Confederat...  todayilearned  137547\n",
       "2  TIL of Dr. Donald Hopkins. He helped eradicate...  todayilearned  134330\n",
       "3  TIL A Japanese company has awarded its non-smo...  todayilearned  131958\n",
       "4  TIL Madonna leaked a fake version of her album...  todayilearned  124754"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "til_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
